{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa7811b2-a58c-4b2a-8f89-6613800d8755",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bdcaf6e0-35b8-48d7-9694-2ca12c0aa4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.preprocessing import LabelEncoder, OrdinalEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c12cc190-4628-4cc7-9e19-1fdb3537cb7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "sys.path.append(project_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e2f7585-5f6a-4c0d-b3af-b957a2dfbc02",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = os.path.join(project_root, 'outputs')\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e81f6eb-1466-4dd6-adff-75559d734cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fairness.losses import fair_bce_loss, calculate_alpha\n",
    "from fairness.metrics import accuracy_equality, statistical_parity, equal_opportunity, predictive_equality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32f9862a-0e9b-4ace-a0d9-489817f098f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed=123):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b5ed667-2ce7-4396-9053-709c18938e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed1cfb46-4280-4199-9db4-74074b9182e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Selecting GPU if configured\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5775482e-06dd-4aba-9f67-dbded70a4b18",
   "metadata": {},
   "source": [
    "## Load & Transform Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "616c043e-2eac-43c1-a961-c3c853f29a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = fetch_openml(\"adult\", version=2, as_frame=True)\n",
    "df = dataset.data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6fec9110-8fc5-48e4-b0af-b5020a57a7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['target'] = dataset.target\n",
    "df['sex'] = LabelEncoder().fit_transform(df['sex'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0874c0c5-b12f-43a6-aa40-d494fb963fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling NaN values\n",
    "if \"Unknown\" not in df['native-country'].cat.categories:\n",
    "    df['native-country'] = df['native-country'].cat.add_categories([\"Unknown\"])\n",
    "df['native-country'] = df['native-country'].fillna(\"Unknown\")\n",
    "\n",
    "if \"Unemployed\" not in df['workclass'].cat.categories:\n",
    "    df['workclass'] = df['workclass'].cat.add_categories([\"Unemployed\"])\n",
    "df['workclass'] = df['workclass'].fillna(\"Unemployed\")\n",
    "\n",
    "if \"Unemployed\" not in df['occupation'].cat.categories:\n",
    "    df['occupation'] = df['occupation'].cat.add_categories([\"Unemployed\"])\n",
    "df['occupation'] = df['occupation'].fillna(\"Unemployed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dc339e0c-06f5-45f2-8c6b-3e99465b66ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features selection and Transformation\n",
    "selected_cols = ['age', 'workclass', 'education-num', 'marital-status', 'occupation', 'relationship',\n",
    "                 'race', 'sex', 'capital-gain', 'capital-loss', 'hours-per-week', 'native-country']\n",
    "X = OrdinalEncoder().fit_transform(df[selected_cols])\n",
    "X = pd.DataFrame(X, columns=selected_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2cde5316-7366-45a9-be44-b2f3d323a4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target selection and Transformation\n",
    "y = LabelEncoder().fit_transform(df['target'])\n",
    "y = pd.DataFrame(y, columns=['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e0206e4a-84c6-4ad3-ac32-9bbd692eebc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train, validation, test split\n",
    "X_train, X_valtest, y_train, y_valtest, sex_train, sex_valtest = train_test_split(\n",
    "    X, y, df['sex'], test_size=0.3, random_state=42, stratify=df['sex']\n",
    ")\n",
    "\n",
    "X_val, X_test, y_val, y_test, sex_val, sex_test = train_test_split(\n",
    "    X_valtest, y_valtest, sex_valtest, test_size = 0.5, random_state=42, stratify=sex_valtest\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b0676224-3e4e-4912-9e86-6cd4a4a296db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standarization\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = torch.tensor(scaler.fit_transform(X_train), dtype=torch.float32)\n",
    "X_val = torch.tensor(scaler.transform(X_val), dtype=torch.float32)\n",
    "X_test = torch.tensor(scaler.transform(X_test), dtype=torch.float32)\n",
    "\n",
    "y_train = torch.tensor(y_train.values, dtype=torch.float32)\n",
    "y_val = torch.tensor(y_val.values, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test.values, dtype=torch.float32)\n",
    "\n",
    "sex_train = torch.tensor(sex_train.values, dtype=torch.float32)\n",
    "sex_val = torch.tensor(sex_val.values, dtype=torch.float32)\n",
    "sex_test = torch.tensor(sex_test.values, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6510537b-822e-460f-94f9-330cf25c2e40",
   "metadata": {},
   "source": [
    "## Creating ML Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "050d14d2-2dcb-45ce-a0fb-9cb4a2458c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP Model\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 64)\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.fc3 = nn.Linear(32, 16)\n",
    "        self.fc4 = nn.Linear(16, 8)\n",
    "        self.fc5 = nn.Linear(8, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "       \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.relu(self.fc3(x))\n",
    "        x = self.relu(self.fc4(x))\n",
    "        x = self.sigmoid(self.fc5(x))\n",
    "        return x  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "53c71e12-183d-49e2-879b-23fbfe586523",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression Model\n",
    "class LogisticRegression(nn.Module):\n",
    "    def __init__(self, input_dim) :\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.linear = nn.Linear(input_dim, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x): \n",
    "        return self.sigmoid(self.linear(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5e718356-0d23-4d35-ae23-a0a90f231f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading ML Model\n",
    "def load_ml_model(ml_algorithm=\"None\"):\n",
    "    if ml_algorithm == \"LR\":\n",
    "        return LogisticRegression(input_dim=X_train.shape[1])\n",
    "    elif ml_algorithm == \"MLP\":\n",
    "        return MLP(input_dim=X_train.shape[1])\n",
    "    else: \n",
    "        raise ValueError(f\"Unsupported ML algorithm: {ml_algorithm}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf70788-f469-42f0-a412-4653096c1968",
   "metadata": {},
   "source": [
    "## Training & Validating Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "16e1a64a-6daf-42ac-afaa-a42c775d0c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, optimizer, epochs, patience, alpha, alpha_mode, fairness_mode):\n",
    "    best_val_acc = 0.0\n",
    "    best_model_state = None\n",
    "    epochs_no_improve = 0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(X_train)\n",
    "        current_alpha = calculate_alpha(epoch, epochs, alpha, alpha_mode)\n",
    "        loss = fair_bce_loss(outputs, y_train, sex_train, alpha=current_alpha, fairness_mode=fairness_mode)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_outputs = model(X_val)\n",
    "            acc_val = ((val_outputs > 0.5).float() == y_val).float().mean().item()\n",
    "\n",
    "        if acc_val > best_val_acc:\n",
    "            best_val_acc = acc_val\n",
    "            best_model_state = model.state_dict()\n",
    "            epochs_no_improve = 0\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "\n",
    "        if epochs_no_improve > patience:\n",
    "            break\n",
    "\n",
    "    return best_model_state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2489d9bc-c14f-4ac2-b734-f3218b97627c",
   "metadata": {},
   "source": [
    "## Testing Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d4e9581f-aece-48d7-8ebc-e96a10bedd07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, fairness_mode):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        test_outputs = model(X_test)\n",
    "        test_preds = (test_outputs > 0.5).float()\n",
    "        test_acc = (test_preds == y_test).float().mean().item()\n",
    "\n",
    "        if fairness_mode == \"AE\":\n",
    "            fairness_score, _ = accuracy_equality(test_outputs.squeeze(), y_test, sex_test)\n",
    "        elif fairness_mode == \"SP\":\n",
    "            fairness_score, _ = statistical_parity(test_outputs, sex_test)\n",
    "        elif fairness_mode == \"EOP\":\n",
    "            fairness_score, _ = equal_opportunity(test_outputs, y_test.squeeze(), sex_test)\n",
    "        elif fairness_mode == \"PE\":\n",
    "            fairness_score, _ = predictive_equality(test_outputs, y_test.squeeze(), sex_test)\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported fairness mode: {fairness_mode}\")\n",
    "\n",
    "    return test_acc, fairness_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f1ae77-ce02-4a5e-9e46-2f91ea4536f3",
   "metadata": {},
   "source": [
    "## Main functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4979363d-5281-403c-b98e-e96ac7c4efc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_results(results, output_dir, model_score, model_acc, model_fair):\n",
    "    # Save models\n",
    "    torch.save(model_score, os.path.join(output_dir, \"best_model_score.pth\"))\n",
    "    torch.save(model_acc, os.path.join(output_dir, \"best_model_acc.pth\"))\n",
    "    torch.save(model_fair, os.path.join(output_dir, \"best_model_fair.pth\"))\n",
    "\n",
    "    # Save CSV\n",
    "    df_results = pd.DataFrame(results)\n",
    "    results_file = os.path.join(output_dir, \"results.csv\")\n",
    "    file_exists = os.path.exists(results_file)\n",
    "    df_results.to_csv(results_file, mode='a', header=not file_exists, index=False)\n",
    "    \n",
    "    return df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2636f81b-9954-42e4-9986-093620db6915",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_all_experiments(ml_algorithm, epochs, alpha_values, alpha_modes, fairness_mode, patience=100):\n",
    "    results = []\n",
    "\n",
    "    best_score, best_acc, best_fairness = -float(\"inf\"), -float(\"inf\"), float(\"inf\")\n",
    "    best_model_score, best_model_acc, best_model_fair = None, None, None\n",
    "    best_result_score, best_result_acc, best_result_fair = None, None, None\n",
    "\n",
    "    for alpha in alpha_values:\n",
    "        for alpha_mode in alpha_modes:\n",
    "            print(f\"\\nRunning {ml_algorithm} | alpha={alpha}, mode={alpha_mode}, fairness={fairness_mode}\")\n",
    "\n",
    "            model = load_ml_model(ml_algorithm)\n",
    "            optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "            best_model_state = train_model(model, optimizer, epochs, patience, alpha, alpha_mode, fairness_mode)\n",
    "            model.load_state_dict(best_model_state)\n",
    "\n",
    "            test_acc, fairness_score = test_model(model, fairness_mode)\n",
    "\n",
    "            print(f\"Test Accuracy: {test_acc:.3f}, {fairness_mode}: {fairness_score:.3f}\")\n",
    "\n",
    "            result_row = {\n",
    "                \"ml_algorithm\": ml_algorithm,\n",
    "                \"fairness_mode\": fairness_mode,\n",
    "                \"fairness_score\": fairness_score,\n",
    "                \"test_accuracy\": test_acc,\n",
    "                \"alpha_mode\": alpha_mode,\n",
    "                \"alpha_value\": alpha\n",
    "            }\n",
    "\n",
    "            results.append(result_row)\n",
    "\n",
    "            score = test_acc - fairness_score\n",
    "\n",
    "            # Best score\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_model_score = best_model_state\n",
    "                best_result_score = result_row\n",
    "\n",
    "            # Best accuracy\n",
    "            if test_acc > best_acc or (test_acc == best_acc and fairness_score < best_result_acc[\"fairness_score\"]):\n",
    "                best_acc = test_acc\n",
    "                best_model_acc = best_model_state\n",
    "                best_result_acc = result_row\n",
    "\n",
    "            # Best fairness (lowest value)\n",
    "            if fairness_score < best_fairness or (fairness_score == best_fairness and test_acc > best_result_fair[\"test_accuracy\"]):\n",
    "                best_fairness = fairness_score\n",
    "                best_model_fair = best_model_state\n",
    "                best_result_fair = result_row\n",
    "\n",
    "    # Report best results\n",
    "    print(\"\\nBest score config:\", best_result_score)\n",
    "    print(\"\\nBest accuracy config:\", best_result_acc)\n",
    "    print(\"\\nBest fairness config:\", best_result_fair)\n",
    "\n",
    "    df_results = save_results(results, output_dir, best_model_score, best_model_acc, best_model_fair)\n",
    "    \n",
    "    return df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e9e3286-0da0-43f1-ae99-41a136d9ce59",
   "metadata": {},
   "source": [
    "## User Input + Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "95a4ba9c-2beb-4d7c-ac3a-aa81cf4b422d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running MLP | alpha=0.0, mode=const, fairness=SP\n",
      "Test Accuracy: 0.246, SP: 0.000\n",
      "\n",
      "Running MLP | alpha=0.0, mode=linear_increase, fairness=SP\n",
      "Test Accuracy: 0.754, SP: 0.000\n",
      "\n",
      "Running MLP | alpha=0.0, mode=linear_decrease, fairness=SP\n",
      "Test Accuracy: 0.843, SP: 0.174\n",
      "\n",
      "Running MLP | alpha=0.1, mode=const, fairness=SP\n",
      "Test Accuracy: 0.754, SP: 0.000\n",
      "\n",
      "Running MLP | alpha=0.1, mode=linear_increase, fairness=SP\n",
      "Test Accuracy: 0.809, SP: 0.006\n",
      "\n",
      "Running MLP | alpha=0.1, mode=linear_decrease, fairness=SP\n",
      "Test Accuracy: 0.843, SP: 0.121\n",
      "\n",
      "Running MLP | alpha=0.2, mode=const, fairness=SP\n",
      "Test Accuracy: 0.805, SP: 0.003\n",
      "\n",
      "Running MLP | alpha=0.2, mode=linear_increase, fairness=SP\n",
      "Test Accuracy: 0.823, SP: 0.022\n",
      "\n",
      "Running MLP | alpha=0.2, mode=linear_decrease, fairness=SP\n",
      "Test Accuracy: 0.839, SP: 0.060\n",
      "\n",
      "Running MLP | alpha=0.3, mode=const, fairness=SP\n",
      "Test Accuracy: 0.813, SP: 0.014\n",
      "\n",
      "Running MLP | alpha=0.3, mode=linear_increase, fairness=SP\n",
      "Test Accuracy: 0.832, SP: 0.037\n",
      "\n",
      "Running MLP | alpha=0.3, mode=linear_decrease, fairness=SP\n",
      "Test Accuracy: 0.835, SP: 0.035\n",
      "\n",
      "Running MLP | alpha=0.4, mode=const, fairness=SP\n",
      "Test Accuracy: 0.820, SP: 0.020\n",
      "\n",
      "Running MLP | alpha=0.4, mode=linear_increase, fairness=SP\n",
      "Test Accuracy: 0.829, SP: 0.011\n",
      "\n",
      "Running MLP | alpha=0.4, mode=linear_decrease, fairness=SP\n",
      "Test Accuracy: 0.830, SP: 0.018\n",
      "\n",
      "Running MLP | alpha=0.5, mode=const, fairness=SP\n",
      "Test Accuracy: 0.825, SP: 0.002\n",
      "\n",
      "Running MLP | alpha=0.5, mode=linear_increase, fairness=SP\n",
      "Test Accuracy: 0.837, SP: 0.059\n",
      "\n",
      "Running MLP | alpha=0.5, mode=linear_decrease, fairness=SP\n",
      "Test Accuracy: 0.830, SP: 0.016\n",
      "\n",
      "Running MLP | alpha=0.6, mode=const, fairness=SP\n",
      "Test Accuracy: 0.828, SP: 0.007\n",
      "\n",
      "Running MLP | alpha=0.6, mode=linear_increase, fairness=SP\n",
      "Test Accuracy: 0.838, SP: 0.065\n",
      "\n",
      "Running MLP | alpha=0.6, mode=linear_decrease, fairness=SP\n",
      "Test Accuracy: 0.834, SP: 0.043\n",
      "\n",
      "Running MLP | alpha=0.7, mode=const, fairness=SP\n",
      "Test Accuracy: 0.836, SP: 0.036\n",
      "\n",
      "Running MLP | alpha=0.7, mode=linear_increase, fairness=SP\n",
      "Test Accuracy: 0.830, SP: 0.013\n",
      "\n",
      "Running MLP | alpha=0.7, mode=linear_decrease, fairness=SP\n",
      "Test Accuracy: 0.827, SP: 0.009\n",
      "\n",
      "Running MLP | alpha=0.8, mode=const, fairness=SP\n",
      "Test Accuracy: 0.842, SP: 0.077\n",
      "\n",
      "Running MLP | alpha=0.8, mode=linear_increase, fairness=SP\n",
      "Test Accuracy: 0.835, SP: 0.039\n",
      "\n",
      "Running MLP | alpha=0.8, mode=linear_decrease, fairness=SP\n",
      "Test Accuracy: 0.823, SP: 0.011\n",
      "\n",
      "Running MLP | alpha=0.9, mode=const, fairness=SP\n",
      "Test Accuracy: 0.849, SP: 0.128\n",
      "\n",
      "Running MLP | alpha=0.9, mode=linear_increase, fairness=SP\n",
      "Test Accuracy: 0.846, SP: 0.134\n",
      "\n",
      "Running MLP | alpha=0.9, mode=linear_decrease, fairness=SP\n",
      "Test Accuracy: 0.820, SP: 0.012\n",
      "\n",
      "Running MLP | alpha=1.0, mode=const, fairness=SP\n",
      "Test Accuracy: 0.849, SP: 0.169\n",
      "\n",
      "Running MLP | alpha=1.0, mode=linear_increase, fairness=SP\n",
      "Test Accuracy: 0.844, SP: 0.162\n",
      "\n",
      "Running MLP | alpha=1.0, mode=linear_decrease, fairness=SP\n",
      "Test Accuracy: 0.822, SP: 0.009\n",
      "\n",
      "Best score config: {'ml_algorithm': 'MLP', 'fairness_mode': 'SP', 'fairness_score': 0.0024454444646835327, 'test_accuracy': 0.8248942494392395, 'alpha_mode': 'const', 'alpha_value': 0.5}\n",
      "\n",
      "Best accuracy config: {'ml_algorithm': 'MLP', 'fairness_mode': 'SP', 'fairness_score': 0.16863413155078888, 'test_accuracy': 0.8494608998298645, 'alpha_mode': 'const', 'alpha_value': 1.0}\n",
      "\n",
      "Best fairness config: {'ml_algorithm': 'MLP', 'fairness_mode': 'SP', 'fairness_score': 0.0, 'test_accuracy': 0.7540603280067444, 'alpha_mode': 'linear_increase', 'alpha_value': 0.0}\n"
     ]
    }
   ],
   "source": [
    "df = run_all_experiments(\n",
    "    ml_algorithm=\"MLP\",  # Models: MLP, LR\n",
    "    epochs=100,\n",
    "    alpha_values=[0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],  # Alpha range between 0 - 1\n",
    "    alpha_modes=[\"const\", \"linear_increase\", \"linear_decrease\"],  # Alpha modes: const, linear_decrease, linear_increase\n",
    "    fairness_mode=\"SP\"  # Fairness modes: AE, SP, EOP, PE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423c0f50-8403-46cd-917e-8a4068cf6443",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "afenv",
   "language": "python",
   "name": "afenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
